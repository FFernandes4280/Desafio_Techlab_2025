# Agente para AlocaÃ§Ã£o de Custos de Ferramentas

## ğŸ“Œ VisÃ£o Geral do Projeto

Este projeto foi desenvolvido como parte do desafio **TechLab 2025**. A proposta consistia na criaÃ§Ã£o de um **agente inteligente** capaz de:

- Receber diversas planilhas externas com informaÃ§Ãµes de custos de ferramentas e benefÃ­cios;
- Padronizar, normalizar e integrar esses dados Ã  **planilha principal de colaboradores** da empresa;
- Permitir a anÃ¡lise conversacional dos resultados por meio de um chatbot intuitivo.

O sistema automatiza tarefas de prÃ©-processamento de dados, realizando desde a leitura de arquivos atÃ© a transformaÃ§Ã£o e fusÃ£o de planilhas. Ao final, o usuÃ¡rio pode interagir com os dados por meio de perguntas em linguagem natural.

---

## ğŸ¯ Desafios Abordados e SoluÃ§Ãµes Implementadas

### ğŸ”§ 1. OrquestraÃ§Ã£o Inteligente de LLMs e Tools

**Desafio**: Usar um modelo de linguagem (LLM) para **selecionar e acionar ferramentas Python externas** de maneira autÃ´noma, com decisÃµes contextuais sobre qual usar e quando.

**SoluÃ§Ã£o**:

- Foram criadas ferramentas (`@tool` via LangChain) especÃ­ficas para manipulaÃ§Ã£o de `DataFrames`, como: ler arquivos, renomear colunas e padronizar CPFs.
- A **LLaMA 4 (llama-4-scout-17b-16e-instruct)** foi utilizada por sua capacidade de **compreensÃ£o contextual avanÃ§ada**, sendo a responsÃ¡vel por tomar decisÃµes complexas, encadear chamadas de ferramentas e lidar com fluxos longos de raciocÃ­nio.
- O modelo Ã© guiado por **prompts otimizados**, que descrevem o funcionamento e o objetivo de cada ferramenta, permitindo que ele forneÃ§a argumentos corretos mesmo em chamadas compostas.

> ReferÃªncia: [GROQ Tool Use Documentation](https://console.groq.com/docs/tool-use)

---

### ğŸ“¥ 2. Coleta Abrangente de Dados

**Desafio**: Detectar automaticamente todas as planilhas em um diretÃ³rio e subdiretÃ³rios, sem omitir arquivos importantes.

**SoluÃ§Ã£o**:

- CriaÃ§Ã£o de uma ferramenta para escanear todos os arquivos `.xlsx` em diretÃ³rios e subpastas usando `os.walk`.
- A leitura Ã© feita de forma manual e sequencial, permitindo que o agente (LLM) processe um DataFrame por vez, garantindo maior controle e precisÃ£o nas prÃ³ximas etapas.

---

### ğŸ“‘ 3. PadronizaÃ§Ã£o de Nomes de Colunas

**Desafio**: Padronizar colunas com nomes diferentes que representam a mesma informaÃ§Ã£o.

**SoluÃ§Ã£o**:

- Inicialmente, foi desenvolvida uma funÃ§Ã£o Python padrÃ£o capaz de receber um nome de coluna atual e o nome padronizado desejado para a alteraÃ§Ã£o. Essa etapa permitia a padronizaÃ§Ã£o de forma manual.
- Posteriormente, o projeto evoluiu para integrar a autonomia do agente (LLM).
- A LLaMA 4 utiliza essa `@tool`, escolhendo os nomes corretos com base em um **prompt que define equivalÃªncias** (ex: "Documento" â†’ "CPF").
- Essa lÃ³gica garante consistÃªncia na estrutura final dos dados.

---

### ğŸ”  4. NormalizaÃ§Ã£o de Dados-Chave

**Desafio**: Padronizar a coluna-chave (CPF), lidando com formatos variados e placeholders.

**SoluÃ§Ã£o**:

- ImplementaÃ§Ã£o de uma funÃ§Ã£o para reformatar todos os CPFs no padrÃ£o `DDD.DDD.DDD-DD`.
- E valores monetÃ¡rios para um formato numÃ©rico limpo (float), removendo sÃ­mbolos de moeda (ex: 'R$', '$') e separadores de milhar (ex: vÃ­rgulas).
- A chamada da funÃ§Ã£o de normalizaÃ§Ã£o Ã© feita pelo agente (LLM) como uma `tool`, guiado por um prompt que especifica o formato exato esperado.
- Isso evita duplicaÃ§Ãµes e falhas na mesclagem dos dados.

**ObservaÃ§Ã£o**:
- Durante o desenvolvimento, a normalizaÃ§Ã£o de valores totais complexos de cada ferramenta (que exigiria um raciocÃ­nio mais aprofundado do LLM sobre cÃ¡lculos e contextos cruzados) foi testada. No entanto, o modelo se mostrou com dificuldade em 
  aplicar essa instruÃ§Ã£o complexa de forma consistente, a menos que o tamanho do lote fosse reduzido a 1. Dada a trade-off entre performance (token/chamadas) e a complexidade da instruÃ§Ã£o, esse tipo de normalizaÃ§Ã£o mais avanÃ§ada nÃ£o foi incluÃ­do 
  na versÃ£o final para garantir a robustez e eficiÃªncia do sistema atual.

---

### ğŸ“Š 5. Gerenciamento de Grandes Volumes de Dados

**Desafio**: Processar `DataFrames` extensos respeitando o limite de tokens da API do LLM e mantendo a acurÃ¡cia.

**SoluÃ§Ã£o**:

- DivisÃ£o dos dados em **batches menores**, garantindo que cada fatia caso o DataFrame seja muito grande nÃ£o ultrapasse o limite de tokens ou por meio da reduÃ§Ã£o do tamanho da batch,
  os resultados sejam mais precisos.
- Cada lote processado atualiza progressivamente o DataFrame principal, que serÃ¡ mesclado ao final.

---

### ğŸ’¬ 6. AnÃ¡lise de Dados Conversacional com RAG

**Desafio**: Permitir que usuÃ¡rios faÃ§am perguntas em linguagem natural sobre os dados consolidados.

**SoluÃ§Ã£o**:

- ApÃ³s a fusÃ£o e padronizaÃ§Ã£o dos dados, o arquivo `result.xlsx` Ã© convertido em um Ã­ndice vetorial com embeddings.
- O modelo **LLaMA 3.3 (llama3-8b-8192)** foi escolhido aqui por sua leveza e eficiÃªncia em tarefas de **pergunta-resposta** baseada em contexto recuperado.
- Aqui o **Retrieval Augmented Generation (RAG)** busca trechos relevantes nos dados vetorizados e passa-os como contexto para o modelo gerar respostas precisas.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python** (linguagem principal)
- **Pandas**: ManipulaÃ§Ã£o de dados tabulares
- **LangChain**: Framework para agentes LLM e definiÃ§Ã£o de tools
- **Groq API**: Fornece acesso aos modelos LLaMA 3.3 e 4
- **HuggingFace Embeddings**: GeraÃ§Ã£o de vetores para o RAG
- **FAISS**: Vetor store local para busca eficiente
- **python-dotenv**: Gerenciamento seguro de variÃ¡veis de ambiente

### Modelos LLM Utilizados:

- **`llama-4-scout-17b-16e-instruct`** (via Groq):
  - ResponsÃ¡vel pela orquestraÃ§Ã£o de tools, anÃ¡lise de DataFrames e prÃ©-processamento.
  - Ideal para tarefas com mÃºltiplos passos e tomada de decisÃ£o autÃ´noma.

- **`llama3-8b-8192`** (via Groq):
  - Utilizado no chatbot com RAG.
  - Otimizado para performance e velocidade em consultas baseadas em dados estruturados.

---

## ğŸš€ Como Usar

### 1. PrÃ©-requisitos

- Python 3.8+
- Conta na Groq com chave de API vÃ¡lida

### 2. InstalaÃ§Ã£o

```bash
git clone https://github.com/FFernandes4280/Desafio_Techlab_2025.git
cd Desafio_Techlab_2025
```
Crie o arquivo .env com a sua chave da GROQ:
```bash
GROQ_API_KEY="SUA_CHAVE_API_DA_GROQ_AQUI"
```
A estrutura esperada do repositorio serÃ¡:
``` bash
.
â”œâ”€â”€ app.py
â”œâ”€â”€ .env
â”œâ”€â”€ result.xlsx (gerado automaticamente)
â”œâ”€â”€ Planilhas/
â”‚   â”œâ”€â”€ Dados Colaboradores.xlsx
â”‚   â”œâ”€â”€ Ferramentas/
â”‚   â”‚   â””â”€â”€ Github.xlsx
â”‚   â””â”€â”€ Beneficios/
â”‚       â””â”€â”€ Unimed.xlsx
â””â”€â”€ tools/
    â”œâ”€â”€ load_files.py
    â”œâ”€â”€ standardize_files.py
    â””â”€â”€ normalize_df.py
```
Finalmente, execute com:
``` bash
python app.py
```

ğŸ¥ [Clique aqui para ver o vÃ­deo de demonstraÃ§Ã£o](ExemploDeUso.mp4)

# ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o muito bem-vindas! Se vocÃª tiver sugestÃµes de melhorias, encontrar bugs ou quiser adicionar novas funcionalidades, sinta-se Ã  vontade para:

1 - Abrir uma Issue descrevendo sua ideia ou problema.

2 - Criar um Pull Request com suas alteraÃ§Ãµes.

